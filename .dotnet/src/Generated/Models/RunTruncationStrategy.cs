// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;

namespace OpenAI.Assistants
{
    /// <summary> Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run. </summary>
    public partial class RunTruncationStrategy
    {
        /// <summary> Initializes a new instance of <see cref="RunTruncationStrategy"/>. </summary>
        /// <param name="type"> The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`. </param>
        /// <param name="lastMessages"> The number of most recent messages from the thread when constructing the context for the run. </param>
        /// <param name="serializedAdditionalRawData"> Keeps track of any properties unknown to the library. </param>
        internal RunTruncationStrategy(InternalRunTruncationStrategyType type, int? lastMessages, IDictionary<string, BinaryData> serializedAdditionalRawData)
        {
            _type = type;
            LastMessages = lastMessages;
            _serializedAdditionalRawData = serializedAdditionalRawData;
        }

        /// <summary> Initializes a new instance of <see cref="RunTruncationStrategy"/> for deserialization. </summary>
        internal RunTruncationStrategy()
        {
        }
    }
}
