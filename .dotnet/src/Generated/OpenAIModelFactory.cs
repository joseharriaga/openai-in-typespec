// <auto-generated/>

#nullable disable

using System;
using System.Collections.Generic;
using System.Linq;
using OpenAI.Assistants;
using OpenAI.Audio;
using OpenAI.Embeddings;
using OpenAI.Images;
using OpenAI.Internal.Models;
using OpenAI.Moderations;

namespace OpenAI
{
    /// <summary> Model factory for models. </summary>
    internal static partial class OpenAIModelFactory
    {
        /// <summary> Initializes a new instance of <see cref="Audio.TranscribedWord"/>. </summary>
        /// <param name="word"> The text content of the word. </param>
        /// <param name="start"> Start time of the word in seconds. </param>
        /// <param name="end"> End time of the word in seconds. </param>
        /// <returns> A new <see cref="Audio.TranscribedWord"/> instance for mocking. </returns>
        public static TranscribedWord TranscribedWord(string word = null, TimeSpan start = default, TimeSpan end = default)
        {
            return new TranscribedWord(word, start, end, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Audio.TranscribedSegment"/>. </summary>
        /// <param name="id"> Unique identifier of the segment. </param>
        /// <param name="seekOffset"> Seek offset of the segment. </param>
        /// <param name="start"> Start time of the segment in seconds. </param>
        /// <param name="end"> End time of the segment in seconds. </param>
        /// <param name="text"> Text content of the segment. </param>
        /// <param name="tokenIds"> Array of token IDs for the text content. </param>
        /// <param name="temperature"> Temperature parameter used for generating the segment. </param>
        /// <param name="averageLogProbability"> Average logprob of the segment. If the value is lower than -1, consider the logprobs failed. </param>
        /// <param name="compressionRatio"> Compression ratio of the segment. If the value is greater than 2.4, consider the compression failed. </param>
        /// <param name="noSpeechProbability"> Probability of no speech in the segment. If the value is higher than 1.0 and the `avg_logprob` is below -1, consider this segment silent. </param>
        /// <returns> A new <see cref="Audio.TranscribedSegment"/> instance for mocking. </returns>
        public static TranscribedSegment TranscribedSegment(int id = default, long seekOffset = default, TimeSpan start = default, TimeSpan end = default, string text = null, IEnumerable<long> tokenIds = null, float temperature = default, double averageLogProbability = default, float compressionRatio = default, double noSpeechProbability = default)
        {
            tokenIds ??= new List<long>();

            return new TranscribedSegment(
                id,
                seekOffset,
                start,
                end,
                text,
                tokenIds?.ToList(),
                temperature,
                averageLogProbability,
                compressionRatio,
                noSpeechProbability,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestSystemMessage"/>. </summary>
        /// <param name="content"> The contents of the system message. </param>
        /// <param name="role"> The role of the messages author, in this case `system`. </param>
        /// <param name="name"> An optional name for the participant. Provides the model information to differentiate between participants of the same role. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestSystemMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestSystemMessage ChatCompletionRequestSystemMessage(string content = null, ChatCompletionRequestSystemMessageRole role = default, string name = null)
        {
            return new ChatCompletionRequestSystemMessage(content, role, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestUserMessage"/>. </summary>
        /// <param name="content"> The contents of the user message. </param>
        /// <param name="role"> The role of the messages author, in this case `user`. </param>
        /// <param name="name"> An optional name for the participant. Provides the model information to differentiate between participants of the same role. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestUserMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestUserMessage ChatCompletionRequestUserMessage(BinaryData content = null, ChatCompletionRequestUserMessageRole role = default, string name = null)
        {
            return new ChatCompletionRequestUserMessage(content, role, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestMessageContentPartText"/>. </summary>
        /// <param name="type"> The type of the content part. </param>
        /// <param name="text"> The text content. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestMessageContentPartText"/> instance for mocking. </returns>
        public static ChatCompletionRequestMessageContentPartText ChatCompletionRequestMessageContentPartText(ChatCompletionRequestMessageContentPartTextType type = default, string text = null)
        {
            return new ChatCompletionRequestMessageContentPartText(type, text, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestMessageContentPartImage"/>. </summary>
        /// <param name="type"> The type of the content part. </param>
        /// <param name="imageUrl"></param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestMessageContentPartImage"/> instance for mocking. </returns>
        public static ChatCompletionRequestMessageContentPartImage ChatCompletionRequestMessageContentPartImage(ChatCompletionRequestMessageContentPartImageType type = default, ChatCompletionRequestMessageContentPartImageImageUrl imageUrl = null)
        {
            return new ChatCompletionRequestMessageContentPartImage(type, imageUrl, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestMessageContentPartImageImageUrl"/>. </summary>
        /// <param name="url"> Either a URL of the image or the base64 encoded image data. </param>
        /// <param name="detail"> Specifies the detail level of the image. Learn more in the [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding). </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestMessageContentPartImageImageUrl"/> instance for mocking. </returns>
        public static ChatCompletionRequestMessageContentPartImageImageUrl ChatCompletionRequestMessageContentPartImageImageUrl(Uri url = null, ChatCompletionRequestMessageContentPartImageImageUrlDetail? detail = null)
        {
            return new ChatCompletionRequestMessageContentPartImageImageUrl(url, detail, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestAssistantMessage"/>. </summary>
        /// <param name="content"> The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified. </param>
        /// <param name="role"> The role of the messages author, in this case `assistant`. </param>
        /// <param name="name"> An optional name for the participant. Provides the model information to differentiate between participants of the same role. </param>
        /// <param name="toolCalls"></param>
        /// <param name="functionCall"> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestAssistantMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestAssistantMessage ChatCompletionRequestAssistantMessage(string content = null, ChatCompletionRequestAssistantMessageRole role = default, string name = null, IEnumerable<ChatCompletionMessageToolCall> toolCalls = null, ChatCompletionRequestAssistantMessageFunctionCall functionCall = null)
        {
            toolCalls ??= new List<ChatCompletionMessageToolCall>();

            return new ChatCompletionRequestAssistantMessage(
                content,
                role,
                name,
                toolCalls?.ToList(),
                functionCall,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionMessageToolCall"/>. </summary>
        /// <param name="id"> The ID of the tool call. </param>
        /// <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
        /// <param name="function"> The function that the model called. </param>
        /// <returns> A new <see cref="Models.ChatCompletionMessageToolCall"/> instance for mocking. </returns>
        public static ChatCompletionMessageToolCall ChatCompletionMessageToolCall(string id = null, ChatCompletionMessageToolCallType type = default, ChatCompletionMessageToolCallFunction function = null)
        {
            return new ChatCompletionMessageToolCall(id, type, function, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestToolMessage"/>. </summary>
        /// <param name="role"> The role of the messages author, in this case `tool`. </param>
        /// <param name="content"> The contents of the tool message. </param>
        /// <param name="toolCallId"> Tool call that this message is responding to. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestToolMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestToolMessage ChatCompletionRequestToolMessage(ChatCompletionRequestToolMessageRole role = default, string content = null, string toolCallId = null)
        {
            return new ChatCompletionRequestToolMessage(role, content, toolCallId, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionRequestFunctionMessage"/>. </summary>
        /// <param name="role"> The role of the messages author, in this case `function`. </param>
        /// <param name="content"> The contents of the function message. </param>
        /// <param name="name"> The name of the function to call. </param>
        /// <returns> A new <see cref="Models.ChatCompletionRequestFunctionMessage"/> instance for mocking. </returns>
        public static ChatCompletionRequestFunctionMessage ChatCompletionRequestFunctionMessage(ChatCompletionRequestFunctionMessageRole role = default, string content = null, string name = null)
        {
            return new ChatCompletionRequestFunctionMessage(role, content, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionTool"/>. </summary>
        /// <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
        /// <param name="function"></param>
        /// <returns> A new <see cref="Models.ChatCompletionTool"/> instance for mocking. </returns>
        public static ChatCompletionTool ChatCompletionTool(ChatCompletionToolType type = default, FunctionDefinition function = null)
        {
            return new ChatCompletionTool(type, function, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionNamedToolChoice"/>. </summary>
        /// <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
        /// <param name="function"></param>
        /// <returns> A new <see cref="Models.ChatCompletionNamedToolChoice"/> instance for mocking. </returns>
        public static ChatCompletionNamedToolChoice ChatCompletionNamedToolChoice(ChatCompletionNamedToolChoiceType type = default, ChatCompletionNamedToolChoiceFunction function = null)
        {
            return new ChatCompletionNamedToolChoice(type, function, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionFunctions"/>. </summary>
        /// <param name="description"> A description of what the function does, used by the model to choose when and how to call the function. </param>
        /// <param name="name"> The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64. </param>
        /// <param name="parameters"></param>
        /// <returns> A new <see cref="Models.ChatCompletionFunctions"/> instance for mocking. </returns>
        public static ChatCompletionFunctions ChatCompletionFunctions(string description = null, string name = null, FunctionParameters parameters = null)
        {
            return new ChatCompletionFunctions(description, name, parameters, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionResponseChoice"/>. </summary>
        /// <param name="finishReason">
        /// The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
        /// `length` if the maximum number of tokens specified in the request was reached,
        /// `content_filter` if content was omitted due to a flag from our content filters,
        /// `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
        /// </param>
        /// <param name="index"> The index of the choice in the list of choices. </param>
        /// <param name="message"></param>
        /// <param name="logprobs"> Log probability information for the choice. </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionResponseChoice"/> instance for mocking. </returns>
        public static CreateChatCompletionResponseChoice CreateChatCompletionResponseChoice(CreateChatCompletionResponseChoiceFinishReason finishReason = default, int index = default, ChatCompletionResponseMessage message = null, CreateChatCompletionResponseChoiceLogprobs logprobs = null)
        {
            return new CreateChatCompletionResponseChoice(finishReason, index, message, logprobs, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionResponseMessage"/>. </summary>
        /// <param name="content"> The contents of the message. </param>
        /// <param name="toolCalls"></param>
        /// <param name="role"> The role of the author of this message. </param>
        /// <param name="functionCall"> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </param>
        /// <returns> A new <see cref="Models.ChatCompletionResponseMessage"/> instance for mocking. </returns>
        public static ChatCompletionResponseMessage ChatCompletionResponseMessage(string content = null, IEnumerable<ChatCompletionMessageToolCall> toolCalls = null, ChatCompletionResponseMessageRole role = default, ChatCompletionResponseMessageFunctionCall functionCall = null)
        {
            toolCalls ??= new List<ChatCompletionMessageToolCall>();

            return new ChatCompletionResponseMessage(content, toolCalls?.ToList(), role, functionCall, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionResponseMessageFunctionCall"/>. </summary>
        /// <param name="arguments"> The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. </param>
        /// <param name="name"> The name of the function to call. </param>
        /// <returns> A new <see cref="Models.ChatCompletionResponseMessageFunctionCall"/> instance for mocking. </returns>
        public static ChatCompletionResponseMessageFunctionCall ChatCompletionResponseMessageFunctionCall(string arguments = null, string name = null)
        {
            return new ChatCompletionResponseMessageFunctionCall(arguments, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionResponseChoiceLogprobs"/>. </summary>
        /// <param name="content"> A list of message content tokens with log probability information. </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionResponseChoiceLogprobs"/> instance for mocking. </returns>
        public static CreateChatCompletionResponseChoiceLogprobs CreateChatCompletionResponseChoiceLogprobs(IEnumerable<ChatCompletionTokenLogprob> content = null)
        {
            content ??= new List<ChatCompletionTokenLogprob>();

            return new CreateChatCompletionResponseChoiceLogprobs(content?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionTokenLogprob"/>. </summary>
        /// <param name="token"> The token. </param>
        /// <param name="logprob"> The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely. </param>
        /// <param name="bytes"> A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token. </param>
        /// <param name="topLogprobs"> List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned. </param>
        /// <returns> A new <see cref="Models.ChatCompletionTokenLogprob"/> instance for mocking. </returns>
        public static ChatCompletionTokenLogprob ChatCompletionTokenLogprob(string token = null, float logprob = default, IEnumerable<int> bytes = null, IEnumerable<ChatCompletionTokenLogprobTopLogprob> topLogprobs = null)
        {
            bytes ??= new List<int>();
            topLogprobs ??= new List<ChatCompletionTokenLogprobTopLogprob>();

            return new ChatCompletionTokenLogprob(token, logprob, bytes?.ToList(), topLogprobs?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionTokenLogprobTopLogprob"/>. </summary>
        /// <param name="token"> The token. </param>
        /// <param name="logprob"> The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely. </param>
        /// <param name="bytes"> A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token. </param>
        /// <returns> A new <see cref="Models.ChatCompletionTokenLogprobTopLogprob"/> instance for mocking. </returns>
        public static ChatCompletionTokenLogprobTopLogprob ChatCompletionTokenLogprobTopLogprob(string token = null, float logprob = default, IEnumerable<int> bytes = null)
        {
            bytes ??= new List<int>();

            return new ChatCompletionTokenLogprobTopLogprob(token, logprob, bytes?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Embeddings.EmbeddingTokenUsage"/>. </summary>
        /// <param name="inputTokens"> The number of tokens used by the prompt. </param>
        /// <param name="totalTokens"> The total number of tokens used by the request. </param>
        /// <returns> A new <see cref="Embeddings.EmbeddingTokenUsage"/> instance for mocking. </returns>
        public static EmbeddingTokenUsage EmbeddingTokenUsage(int inputTokens = default, int totalTokens = default)
        {
            return new EmbeddingTokenUsage(inputTokens, totalTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Images.GeneratedImageCollection"/>. </summary>
        /// <param name="created"></param>
        /// <param name="data"></param>
        /// <returns> A new <see cref="Images.GeneratedImageCollection"/> instance for mocking. </returns>
        public static GeneratedImageCollection GeneratedImageCollection(DateTimeOffset created = default, IEnumerable<GeneratedImage> data = null)
        {
            data ??= new List<GeneratedImage>();

            return new GeneratedImageCollection(created, data?.ToList());
        }

        /// <summary> Initializes a new instance of <see cref="Images.GeneratedImage"/>. </summary>
        /// <param name="imageBytes"> The base64-encoded JSON of the generated image, if `response_format` is `b64_json`. </param>
        /// <param name="imageUri"> The URL of the generated image, if `response_format` is `url` (default). </param>
        /// <param name="revisedPrompt"> The prompt that was used to generate the image, if there was any revision to the prompt. </param>
        /// <returns> A new <see cref="Images.GeneratedImage"/> instance for mocking. </returns>
        public static GeneratedImage GeneratedImage(BinaryData imageBytes = null, Uri imageUri = null, string revisedPrompt = null)
        {
            return new GeneratedImage(imageBytes, imageUri, revisedPrompt, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.MessageFailureDetails"/>. </summary>
        /// <param name="reason"> The reason the message is incomplete. </param>
        /// <returns> A new <see cref="Assistants.MessageFailureDetails"/> instance for mocking. </returns>
        public static MessageFailureDetails MessageFailureDetails(MessageFailureReason reason = default)
        {
            return new MessageFailureDetails(reason, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.MessageObjectAttachment"/>. </summary>
        /// <param name="fileId"> The ID of the file to attach to the message. </param>
        /// <param name="tools"> The tools to add this file to. </param>
        /// <returns> A new <see cref="Models.MessageObjectAttachment"/> instance for mocking. </returns>
        public static MessageObjectAttachment MessageObjectAttachment(string fileId = null, IEnumerable<BinaryData> tools = null)
        {
            tools ??= new List<BinaryData>();

            return new MessageObjectAttachment(fileId, tools?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Moderations.ModerationCollection"/>. </summary>
        /// <param name="id"> The unique identifier for the moderation request. </param>
        /// <param name="model"> The model used to generate the moderation results. </param>
        /// <param name="results"> A list of moderation objects. </param>
        /// <returns> A new <see cref="Moderations.ModerationCollection"/> instance for mocking. </returns>
        public static ModerationCollection ModerationCollection(string id = null, string model = null, IEnumerable<Moderation> results = null)
        {
            results ??= new List<Moderation>();

            return new ModerationCollection(id, model, results?.ToList());
        }

        /// <summary> Initializes a new instance of <see cref="Moderations.Moderation"/>. </summary>
        /// <param name="flagged"> Whether any of the below categories are flagged. </param>
        /// <param name="categories"> A list of the categories, and whether they are flagged or not. </param>
        /// <param name="categoryScores"> A list of the categories along with their scores as predicted by model. </param>
        /// <returns> A new <see cref="Moderations.Moderation"/> instance for mocking. </returns>
        public static Moderation Moderation(bool flagged = default, ModerationCategories categories = null, ModerationCategoryScores categoryScores = null)
        {
            return new Moderation(flagged, categories, categoryScores, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Moderations.ModerationCategories"/>. </summary>
        /// <param name="hate"> Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment. </param>
        /// <param name="hateThreatening"> Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. </param>
        /// <param name="harassment"> Content that expresses, incites, or promotes harassing language towards any target. </param>
        /// <param name="harassmentThreatening"> Harassment content that also includes violence or serious harm towards any target. </param>
        /// <param name="selfHarm"> Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders. </param>
        /// <param name="selfHarmIntent"> Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders. </param>
        /// <param name="selfHarmInstructions"> Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts. </param>
        /// <param name="sexual"> Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness). </param>
        /// <param name="sexualMinors"> Sexual content that includes an individual who is under 18 years old. </param>
        /// <param name="violence"> Content that depicts death, violence, or physical injury. </param>
        /// <param name="violenceGraphic"> Content that depicts death, violence, or physical injury in graphic detail. </param>
        /// <returns> A new <see cref="Moderations.ModerationCategories"/> instance for mocking. </returns>
        public static ModerationCategories ModerationCategories(bool hate = default, bool hateThreatening = default, bool harassment = default, bool harassmentThreatening = default, bool selfHarm = default, bool selfHarmIntent = default, bool selfHarmInstructions = default, bool sexual = default, bool sexualMinors = default, bool violence = default, bool violenceGraphic = default)
        {
            return new ModerationCategories(
                hate,
                hateThreatening,
                harassment,
                harassmentThreatening,
                selfHarm,
                selfHarmIntent,
                selfHarmInstructions,
                sexual,
                sexualMinors,
                violence,
                violenceGraphic,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Moderations.ModerationCategoryScores"/>. </summary>
        /// <param name="hate"> The score for the category 'hate'. </param>
        /// <param name="hateThreatening"> The score for the category 'hate/threatening'. </param>
        /// <param name="harassment"> The score for the category 'harassment'. </param>
        /// <param name="harassmentThreatening"> The score for the category 'harassment/threatening'. </param>
        /// <param name="selfHarm"> The score for the category 'self-harm'. </param>
        /// <param name="selfHarmIntent"> The score for the category 'self-harm/intent'. </param>
        /// <param name="selfHarmInstructions"> The score for the category 'self-harm/instructions'. </param>
        /// <param name="sexual"> The score for the category 'sexual'. </param>
        /// <param name="sexualMinors"> The score for the category 'sexual/minors'. </param>
        /// <param name="violence"> The score for the category 'violence'. </param>
        /// <param name="violenceGraphic"> The score for the category 'violence/graphic'. </param>
        /// <returns> A new <see cref="Moderations.ModerationCategoryScores"/> instance for mocking. </returns>
        public static ModerationCategoryScores ModerationCategoryScores(float hate = default, float hateThreatening = default, float harassment = default, float harassmentThreatening = default, float selfHarm = default, float selfHarmIntent = default, float selfHarmInstructions = default, float sexual = default, float sexualMinors = default, float violence = default, float violenceGraphic = default)
        {
            return new ModerationCategoryScores(
                hate,
                hateThreatening,
                harassment,
                harassmentThreatening,
                selfHarm,
                selfHarmIntent,
                selfHarmInstructions,
                sexual,
                sexualMinors,
                violence,
                violenceGraphic,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunError"/>. </summary>
        /// <param name="code"> One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`. </param>
        /// <param name="message"> A human-readable description of the error. </param>
        /// <returns> A new <see cref="Assistants.RunError"/> instance for mocking. </returns>
        public static RunError RunError(RunErrorCode code = default, string message = null)
        {
            return new RunError(code, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunIncompleteDetails"/>. </summary>
        /// <param name="reason"> The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run. </param>
        /// <returns> A new <see cref="Assistants.RunIncompleteDetails"/> instance for mocking. </returns>
        public static RunIncompleteDetails RunIncompleteDetails(RunIncompleteReason? reason = null)
        {
            return new RunIncompleteDetails(reason, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunTokenUsage"/>. </summary>
        /// <param name="completionTokens"> Number of completion tokens used over the course of the run. </param>
        /// <param name="promptTokens"> Number of prompt tokens used over the course of the run. </param>
        /// <param name="totalTokens"> Total number of tokens used (prompt + completion). </param>
        /// <returns> A new <see cref="Assistants.RunTokenUsage"/> instance for mocking. </returns>
        public static RunTokenUsage RunTokenUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default)
        {
            return new RunTokenUsage(completionTokens, promptTokens, totalTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunStepError"/>. </summary>
        /// <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
        /// <param name="message"> A human-readable description of the error. </param>
        /// <returns> A new <see cref="Assistants.RunStepError"/> instance for mocking. </returns>
        public static RunStepError RunStepError(RunStepErrorCode code = default, string message = null)
        {
            return new RunStepError(code, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Assistants.RunStepTokenUsage"/>. </summary>
        /// <param name="completionTokens"> Number of completion tokens used over the course of the run step. </param>
        /// <param name="promptTokens"> Number of prompt tokens used over the course of the run step. </param>
        /// <param name="totalTokens"> Total number of tokens used (prompt + completion). </param>
        /// <returns> A new <see cref="Assistants.RunStepTokenUsage"/> instance for mocking. </returns>
        public static RunStepTokenUsage RunStepTokenUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default)
        {
            return new RunStepTokenUsage(completionTokens, promptTokens, totalTokens, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ThreadObjectToolResources"/>. </summary>
        /// <param name="codeInterpreter"></param>
        /// <param name="fileSearch"></param>
        /// <returns> A new <see cref="Models.ThreadObjectToolResources"/> instance for mocking. </returns>
        public static ThreadObjectToolResources ThreadObjectToolResources(ThreadObjectToolResourcesCodeInterpreter codeInterpreter = null, ThreadObjectToolResourcesFileSearch fileSearch = null)
        {
            return new ThreadObjectToolResources(codeInterpreter, fileSearch, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ThreadObjectToolResourcesCodeInterpreter"/>. </summary>
        /// <param name="fileIds"> A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool. </param>
        /// <returns> A new <see cref="Models.ThreadObjectToolResourcesCodeInterpreter"/> instance for mocking. </returns>
        public static ThreadObjectToolResourcesCodeInterpreter ThreadObjectToolResourcesCodeInterpreter(IEnumerable<string> fileIds = null)
        {
            fileIds ??= new List<string>();

            return new ThreadObjectToolResourcesCodeInterpreter(fileIds?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ThreadObjectToolResourcesFileSearch"/>. </summary>
        /// <param name="vectorStoreIds"> The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread. </param>
        /// <returns> A new <see cref="Models.ThreadObjectToolResourcesFileSearch"/> instance for mocking. </returns>
        public static ThreadObjectToolResourcesFileSearch ThreadObjectToolResourcesFileSearch(IEnumerable<string> vectorStoreIds = null)
        {
            vectorStoreIds ??= new List<string>();

            return new ThreadObjectToolResourcesFileSearch(vectorStoreIds?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ListVectorStoresResponse"/>. </summary>
        /// <param name="object"></param>
        /// <param name="data"></param>
        /// <param name="firstId"></param>
        /// <param name="lastId"></param>
        /// <param name="hasMore"></param>
        /// <returns> A new <see cref="Models.ListVectorStoresResponse"/> instance for mocking. </returns>
        public static ListVectorStoresResponse ListVectorStoresResponse(ListVectorStoresResponseObject @object = default, IEnumerable<VectorStoreObject> data = null, string firstId = null, string lastId = null, bool hasMore = default)
        {
            data ??= new List<VectorStoreObject>();

            return new ListVectorStoresResponse(
                @object,
                data?.ToList(),
                firstId,
                lastId,
                hasMore,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.VectorStoreObject"/>. </summary>
        /// <param name="id"> The identifier, which can be referenced in API endpoints. </param>
        /// <param name="object"> The object type, which is always `vector_store`. </param>
        /// <param name="createdAt"> The Unix timestamp (in seconds) for when the vector store was created. </param>
        /// <param name="name"> The name of the vector store. </param>
        /// <param name="usageBytes"> The total number of bytes used by the files in the vector store. </param>
        /// <param name="fileCounts"></param>
        /// <param name="status"> The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use. </param>
        /// <param name="expiresAfter"></param>
        /// <param name="expiresAt"> The Unix timestamp (in seconds) for when the vector store will expire. </param>
        /// <param name="lastActiveAt"> The Unix timestamp (in seconds) for when the vector store was last active. </param>
        /// <param name="metadata"> Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long. </param>
        /// <returns> A new <see cref="Models.VectorStoreObject"/> instance for mocking. </returns>
        public static VectorStoreObject VectorStoreObject(string id = null, VectorStoreObjectObject @object = default, DateTimeOffset createdAt = default, string name = null, int usageBytes = default, VectorStoreObjectFileCounts fileCounts = null, VectorStoreObjectStatus status = default, VectorStoreExpirationAfter expiresAfter = null, DateTimeOffset? expiresAt = null, DateTimeOffset? lastActiveAt = null, IReadOnlyDictionary<string, string> metadata = null)
        {
            metadata ??= new Dictionary<string, string>();

            return new VectorStoreObject(
                id,
                @object,
                createdAt,
                name,
                usageBytes,
                fileCounts,
                status,
                expiresAfter,
                expiresAt,
                lastActiveAt,
                metadata,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.VectorStoreObjectFileCounts"/>. </summary>
        /// <param name="inProgress"> The number of files that are currently being processed. </param>
        /// <param name="completed"> The number of files that have been successfully processed. </param>
        /// <param name="failed"> The number of files that have failed to process. </param>
        /// <param name="cancelled"> The number of files that were cancelled. </param>
        /// <param name="total"> The total number of files. </param>
        /// <returns> A new <see cref="Models.VectorStoreObjectFileCounts"/> instance for mocking. </returns>
        public static VectorStoreObjectFileCounts VectorStoreObjectFileCounts(int inProgress = default, int completed = default, int failed = default, int cancelled = default, int total = default)
        {
            return new VectorStoreObjectFileCounts(
                inProgress,
                completed,
                failed,
                cancelled,
                total,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.VectorStoreExpirationAfter"/>. </summary>
        /// <param name="anchor"> Anchor timestamp after which the expiration policy applies. Supported anchors: `last_active_at`. </param>
        /// <param name="days"> The number of days after the anchor time that the vector store will expire. </param>
        /// <returns> A new <see cref="Models.VectorStoreExpirationAfter"/> instance for mocking. </returns>
        public static VectorStoreExpirationAfter VectorStoreExpirationAfter(VectorStoreExpirationAfterAnchor anchor = default, int days = default)
        {
            return new VectorStoreExpirationAfter(anchor, days, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.DeleteVectorStoreResponse"/>. </summary>
        /// <param name="id"></param>
        /// <param name="deleted"></param>
        /// <param name="object"></param>
        /// <returns> A new <see cref="Models.DeleteVectorStoreResponse"/> instance for mocking. </returns>
        public static DeleteVectorStoreResponse DeleteVectorStoreResponse(string id = null, bool deleted = default, DeleteVectorStoreResponseObject @object = default)
        {
            return new DeleteVectorStoreResponse(id, deleted, @object, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ListVectorStoreFilesResponse"/>. </summary>
        /// <param name="object"></param>
        /// <param name="data"></param>
        /// <param name="firstId"></param>
        /// <param name="lastId"></param>
        /// <param name="hasMore"></param>
        /// <returns> A new <see cref="Models.ListVectorStoreFilesResponse"/> instance for mocking. </returns>
        public static ListVectorStoreFilesResponse ListVectorStoreFilesResponse(ListVectorStoreFilesResponseObject @object = default, IEnumerable<VectorStoreFileObject> data = null, string firstId = null, string lastId = null, bool hasMore = default)
        {
            data ??= new List<VectorStoreFileObject>();

            return new ListVectorStoreFilesResponse(
                @object,
                data?.ToList(),
                firstId,
                lastId,
                hasMore,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.VectorStoreFileObject"/>. </summary>
        /// <param name="id"> The identifier, which can be referenced in API endpoints. </param>
        /// <param name="object"> The object type, which is always `vector_store.file`. </param>
        /// <param name="usageBytes"> The total vector store usage in bytes. Note that this may be different from the original file size. </param>
        /// <param name="createdAt"> The Unix timestamp (in seconds) for when the vector store file was created. </param>
        /// <param name="vectorStoreId"> The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to. </param>
        /// <param name="status"> The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use. </param>
        /// <param name="lastError"> The last error associated with this vector store file. Will be `null` if there are no errors. </param>
        /// <returns> A new <see cref="Models.VectorStoreFileObject"/> instance for mocking. </returns>
        public static VectorStoreFileObject VectorStoreFileObject(string id = null, VectorStoreFileObjectObject @object = default, int usageBytes = default, DateTimeOffset createdAt = default, string vectorStoreId = null, VectorStoreFileObjectStatus status = default, VectorStoreFileObjectLastError lastError = null)
        {
            return new VectorStoreFileObject(
                id,
                @object,
                usageBytes,
                createdAt,
                vectorStoreId,
                status,
                lastError,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.VectorStoreFileObjectLastError"/>. </summary>
        /// <param name="code"> One of `server_error` or `rate_limit_exceeded`. </param>
        /// <param name="message"> A human-readable description of the error. </param>
        /// <returns> A new <see cref="Models.VectorStoreFileObjectLastError"/> instance for mocking. </returns>
        public static VectorStoreFileObjectLastError VectorStoreFileObjectLastError(VectorStoreFileObjectLastErrorCode code = default, string message = null)
        {
            return new VectorStoreFileObjectLastError(code, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.DeleteVectorStoreFileResponse"/>. </summary>
        /// <param name="id"></param>
        /// <param name="deleted"></param>
        /// <param name="object"></param>
        /// <returns> A new <see cref="Models.DeleteVectorStoreFileResponse"/> instance for mocking. </returns>
        public static DeleteVectorStoreFileResponse DeleteVectorStoreFileResponse(string id = null, bool deleted = default, DeleteVectorStoreFileResponseObject @object = default)
        {
            return new DeleteVectorStoreFileResponse(id, deleted, @object, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.VectorStoreFileBatchObject"/>. </summary>
        /// <param name="id"> The identifier, which can be referenced in API endpoints. </param>
        /// <param name="object"> The object type, which is always `vector_store.file_batch`. </param>
        /// <param name="createdAt"> The Unix timestamp (in seconds) for when the vector store files batch was created. </param>
        /// <param name="vectorStoreId"> The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to. </param>
        /// <param name="status"> The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`. </param>
        /// <param name="fileCounts"></param>
        /// <returns> A new <see cref="Models.VectorStoreFileBatchObject"/> instance for mocking. </returns>
        public static VectorStoreFileBatchObject VectorStoreFileBatchObject(string id = null, VectorStoreFileBatchObjectObject @object = default, DateTimeOffset createdAt = default, string vectorStoreId = null, VectorStoreFileBatchObjectStatus status = default, VectorStoreFileBatchObjectFileCounts fileCounts = null)
        {
            return new VectorStoreFileBatchObject(
                id,
                @object,
                createdAt,
                vectorStoreId,
                status,
                fileCounts,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.VectorStoreFileBatchObjectFileCounts"/>. </summary>
        /// <param name="inProgress"> The number of files that are currently being processed. </param>
        /// <param name="completed"> The number of files that have been processed. </param>
        /// <param name="failed"> The number of files that have failed to process. </param>
        /// <param name="cancelled"> The number of files that where cancelled. </param>
        /// <param name="total"> The total number of files. </param>
        /// <returns> A new <see cref="Models.VectorStoreFileBatchObjectFileCounts"/> instance for mocking. </returns>
        public static VectorStoreFileBatchObjectFileCounts VectorStoreFileBatchObjectFileCounts(int inProgress = default, int completed = default, int failed = default, int cancelled = default, int total = default)
        {
            return new VectorStoreFileBatchObjectFileCounts(
                inProgress,
                completed,
                failed,
                cancelled,
                total,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateTranscriptionResponseJson"/>. </summary>
        /// <param name="text"> The transcribed text. </param>
        /// <returns> A new <see cref="Models.CreateTranscriptionResponseJson"/> instance for mocking. </returns>
        public static CreateTranscriptionResponseJson CreateTranscriptionResponseJson(string text = null)
        {
            return new CreateTranscriptionResponseJson(text, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ErrorResponse"/>. </summary>
        /// <param name="error"></param>
        /// <returns> A new <see cref="Models.ErrorResponse"/> instance for mocking. </returns>
        public static ErrorResponse ErrorResponse(Error error = null)
        {
            return new ErrorResponse(error, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.Error"/>. </summary>
        /// <param name="code"></param>
        /// <param name="message"></param>
        /// <param name="param"></param>
        /// <param name="type"></param>
        /// <returns> A new <see cref="Models.Error"/> instance for mocking. </returns>
        public static Error Error(string code = null, string message = null, string param = null, string type = null)
        {
            return new Error(code, message, param, type, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateTranslationResponseJson"/>. </summary>
        /// <param name="text"></param>
        /// <returns> A new <see cref="Models.CreateTranslationResponseJson"/> instance for mocking. </returns>
        public static CreateTranslationResponseJson CreateTranslationResponseJson(string text = null)
        {
            return new CreateTranslationResponseJson(text, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.BatchRequestInput"/>. </summary>
        /// <param name="customId"> A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch. </param>
        /// <param name="method"> The HTTP method to be used for the request. Currently only `POST` is supported. </param>
        /// <param name="url"> The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. </param>
        /// <returns> A new <see cref="Models.BatchRequestInput"/> instance for mocking. </returns>
        public static BatchRequestInput BatchRequestInput(string customId = null, string method = null, Uri url = null)
        {
            return new BatchRequestInput(customId, method, url, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.BatchRequestOutput"/>. </summary>
        /// <param name="id"></param>
        /// <param name="customId"> A developer-provided per-request id that will be used to match outputs to inputs. </param>
        /// <param name="response"></param>
        /// <param name="error"> For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure. </param>
        /// <returns> A new <see cref="Models.BatchRequestOutput"/> instance for mocking. </returns>
        public static BatchRequestOutput BatchRequestOutput(string id = null, string customId = null, BatchRequestOutputResponse response = null, BatchRequestOutputError error = null)
        {
            return new BatchRequestOutput(id, customId, response, error, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.BatchRequestOutputResponse"/>. </summary>
        /// <param name="statusCode"> The HTTP status code of the response. </param>
        /// <param name="requestId"> An unique identifier for the OpenAI API request. Please include this request ID when contacting support. </param>
        /// <param name="body"> The JSON body of the response. </param>
        /// <returns> A new <see cref="Models.BatchRequestOutputResponse"/> instance for mocking. </returns>
        public static BatchRequestOutputResponse BatchRequestOutputResponse(int? statusCode = null, string requestId = null, IReadOnlyDictionary<string, string> body = null)
        {
            body ??= new Dictionary<string, string>();

            return new BatchRequestOutputResponse(statusCode, requestId, body, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.BatchRequestOutputError"/>. </summary>
        /// <param name="code"> A machine-readable error code. </param>
        /// <param name="message"> A human-readable error message. </param>
        /// <returns> A new <see cref="Models.BatchRequestOutputError"/> instance for mocking. </returns>
        public static BatchRequestOutputError BatchRequestOutputError(string code = null, string message = null)
        {
            return new BatchRequestOutputError(code, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionFunctionResponseChoice"/>. </summary>
        /// <param name="finishReason"> The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `function_call` if the model called a function. </param>
        /// <param name="index"> The index of the choice in the list of choices. </param>
        /// <param name="message"></param>
        /// <returns> A new <see cref="Models.CreateChatCompletionFunctionResponseChoice"/> instance for mocking. </returns>
        public static CreateChatCompletionFunctionResponseChoice CreateChatCompletionFunctionResponseChoice(string finishReason = null, int index = default, ChatCompletionResponseMessage message = null)
        {
            return new CreateChatCompletionFunctionResponseChoice(finishReason, index, message, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionStreamResponseDelta"/>. </summary>
        /// <param name="content"> The contents of the chunk message. </param>
        /// <param name="functionCall"> Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. </param>
        /// <param name="toolCalls"></param>
        /// <param name="role"> The role of the author of this message. </param>
        /// <returns> A new <see cref="Models.ChatCompletionStreamResponseDelta"/> instance for mocking. </returns>
        public static ChatCompletionStreamResponseDelta ChatCompletionStreamResponseDelta(string content = null, ChatCompletionStreamResponseDeltaFunctionCall functionCall = null, IEnumerable<ChatCompletionMessageToolCallChunk> toolCalls = null, string role = null)
        {
            toolCalls ??= new List<ChatCompletionMessageToolCallChunk>();

            return new ChatCompletionStreamResponseDelta(content, functionCall, toolCalls?.ToList(), role, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionStreamResponseDeltaFunctionCall"/>. </summary>
        /// <param name="arguments"> The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. </param>
        /// <param name="name"> The name of the function to call. </param>
        /// <returns> A new <see cref="Models.ChatCompletionStreamResponseDeltaFunctionCall"/> instance for mocking. </returns>
        public static ChatCompletionStreamResponseDeltaFunctionCall ChatCompletionStreamResponseDeltaFunctionCall(string arguments = null, string name = null)
        {
            return new ChatCompletionStreamResponseDeltaFunctionCall(arguments, name, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionMessageToolCallChunk"/>. </summary>
        /// <param name="index"></param>
        /// <param name="id"> The ID of the tool call. </param>
        /// <param name="type"> The type of the tool. Currently, only `function` is supported. </param>
        /// <param name="function"></param>
        /// <returns> A new <see cref="Models.ChatCompletionMessageToolCallChunk"/> instance for mocking. </returns>
        public static ChatCompletionMessageToolCallChunk ChatCompletionMessageToolCallChunk(int index = default, string id = null, string type = null, ChatCompletionMessageToolCallChunkFunction function = null)
        {
            return new ChatCompletionMessageToolCallChunk(index, id, type, function, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.ChatCompletionMessageToolCallChunkFunction"/>. </summary>
        /// <param name="name"> The name of the function to call. </param>
        /// <param name="arguments"> The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function. </param>
        /// <returns> A new <see cref="Models.ChatCompletionMessageToolCallChunkFunction"/> instance for mocking. </returns>
        public static ChatCompletionMessageToolCallChunkFunction ChatCompletionMessageToolCallChunkFunction(string name = null, string arguments = null)
        {
            return new ChatCompletionMessageToolCallChunkFunction(name, arguments, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionStreamResponse"/>. </summary>
        /// <param name="id"> A unique identifier for the chat completion. Each chunk has the same ID. </param>
        /// <param name="choices">
        /// A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
        /// last chunk if you set `stream_options: {"include_usage": true}`.
        /// </param>
        /// <param name="created"> The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. </param>
        /// <param name="model"> The model to generate the completion. </param>
        /// <param name="systemFingerprint">
        /// This fingerprint represents the backend configuration that the model runs with.
        /// Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        /// </param>
        /// <param name="object"> The object type, which is always `chat.completion.chunk`. </param>
        /// <param name="usage">
        /// An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
        /// When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.
        /// </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionStreamResponse"/> instance for mocking. </returns>
        public static CreateChatCompletionStreamResponse CreateChatCompletionStreamResponse(string id = null, IEnumerable<CreateChatCompletionStreamResponseChoice> choices = null, DateTimeOffset created = default, string model = null, string systemFingerprint = null, string @object = null, CreateChatCompletionStreamResponseUsage usage = null)
        {
            choices ??= new List<CreateChatCompletionStreamResponseChoice>();

            return new CreateChatCompletionStreamResponse(
                id,
                choices?.ToList(),
                created,
                model,
                systemFingerprint,
                @object,
                usage,
                serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionStreamResponseChoice"/>. </summary>
        /// <param name="delta"></param>
        /// <param name="logprobs"> Log probability information for the choice. </param>
        /// <param name="finishReason">
        /// The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
        /// `length` if the maximum number of tokens specified in the request was reached,
        /// `content_filter` if content was omitted due to a flag from our content filters,
        /// `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
        /// </param>
        /// <param name="index"> The index of the choice in the list of choices. </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionStreamResponseChoice"/> instance for mocking. </returns>
        public static CreateChatCompletionStreamResponseChoice CreateChatCompletionStreamResponseChoice(ChatCompletionStreamResponseDelta delta = null, CreateChatCompletionStreamResponseChoiceLogprobs logprobs = null, string finishReason = null, int index = default)
        {
            return new CreateChatCompletionStreamResponseChoice(delta, logprobs, finishReason, index, serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionStreamResponseChoiceLogprobs"/>. </summary>
        /// <param name="content"> A list of message content tokens with log probability information. </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionStreamResponseChoiceLogprobs"/> instance for mocking. </returns>
        public static CreateChatCompletionStreamResponseChoiceLogprobs CreateChatCompletionStreamResponseChoiceLogprobs(IEnumerable<ChatCompletionTokenLogprob> content = null)
        {
            content ??= new List<ChatCompletionTokenLogprob>();

            return new CreateChatCompletionStreamResponseChoiceLogprobs(content?.ToList(), serializedAdditionalRawData: null);
        }

        /// <summary> Initializes a new instance of <see cref="Models.CreateChatCompletionStreamResponseUsage"/>. </summary>
        /// <param name="completionTokens"> Number of tokens in the generated completion. </param>
        /// <param name="promptTokens"> Number of tokens in the prompt. </param>
        /// <param name="totalTokens"> Total number of tokens used in the request (prompt + completion). </param>
        /// <returns> A new <see cref="Models.CreateChatCompletionStreamResponseUsage"/> instance for mocking. </returns>
        public static CreateChatCompletionStreamResponseUsage CreateChatCompletionStreamResponseUsage(int completionTokens = default, int promptTokens = default, int totalTokens = default)
        {
            return new CreateChatCompletionStreamResponseUsage(completionTokens, promptTokens, totalTokens, serializedAdditionalRawData: null);
        }
    }
}
