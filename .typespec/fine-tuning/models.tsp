import "../chat";
import "../common";
import "./custom.tsp";

using TypeSpec.OpenAPI;

namespace OpenAI;

// Tool generated type. Extracts CreateFineTuningJobRequest.integrations
model CreateFineTuningJobRequestIntegrations
  is CreateFineTuningJobRequestIntegration[];

// Tool generated type. Extracts FineTuningJob.integrations
@maxItems(5)
@extension("x-oaiExpandable", true)
model FineTuningJobIntegrations is FineTuningIntegration[];

model ListPaginatedFineTuningJobsResponse {
  data: FineTuningJob[];
  has_more: boolean;
  object: "list";
}

// Tool customization: Include spec-omitted 'has_more' property
model ListFineTuningJobEventsResponse {
  data: FineTuningJobEvent[];
  object: "list";
  has_more: boolean;
}

model ListFineTuningJobCheckpointsResponse {
  data: FineTuningJobCheckpoint[];
  object: "list";
  first_id?: string | null;
  last_id?: string | null;
  has_more: boolean;
}

// Tool customization: Convert to instantiation of discriminated type
model FineTuningIntegrationWandb extends FineTuningIntegration {
  /** The type of the integration being enabled for the fine-tuning job */
  type: "wandb";

  /**
   * The settings for your integration with Weights and Biases. This payload specifies the project that
   * metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
   * to your run, and set a default entity (team, username, etc) to be associated with your run.
   */
  wandb: {
    /** The name of the project that the new run will be created under. */
    project: string;

    /** A display name to set for the run. If not set, we will use the Job ID as the name. */
    name?: string | null;

    /**
     * The entity to use for the run. This allows you to set the team or username of the WandB user that you would
     * like associated with the run. If not set, the default entity for the registered WandB API key is used.
     */
    entity?: string | null;

    /**
     * A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
     * default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}".
     */
    tags?: string[];
  };
}

/** Fine-tuning job event object */
model FineTuningJobEvent {
  id: string;

  // Tool customization: 'created' and fields ending in '_at' are Unix encoded utcDateTime
  @encode("unixTimestamp", int32)
  created_at: utcDateTime;

  level: "info" | "warn" | "error";
  message: string;
  object: "fine_tuning.job.event";
}

@doc("""
  The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.
  """)
model FineTuningJobCheckpoint {
  /** The checkpoint identifier, which can be referenced in the API endpoints. */
  id: string;

  // Tool customization: 'created' and fields ending in '_at' are Unix encoded utcDateTime
  /** The Unix timestamp (in seconds) for when the checkpoint was created. */
  @encode("unixTimestamp", int32)
  created_at: utcDateTime;

  /** The name of the fine-tuned checkpoint model that is created. */
  fine_tuned_model_checkpoint: string;

  /** The step number that the checkpoint was created at. */
  step_number: int32;

  /** Metrics at the step number during the fine-tuning job. */
  metrics: {
    step: int32;
    train_loss: float32;
    train_mean_token_accuracy: float32;
    valid_loss?: float32;
    valid_mean_token_accuracy?: float32;
    full_valid_loss?: float32;
    full_valid_mean_token_accuracy?: float32;
  };

  /** The name of the fine-tuning job that this checkpoint was created from. */
  fine_tuning_job_id: string;

  /** The object type, which is always "fine_tuning.job.checkpoint". */
  object: "fine_tuning.job.checkpoint";
}

/** The per-line training example of a fine-tuning input file for chat models */
model FinetuneChatRequestInput {
  @minItems(1)
  @extension("x-oaiExpandable", true)
  messages?: (
    | ChatCompletionRequestSystemMessage
    | ChatCompletionRequestUserMessage
    | FineTuneChatCompletionRequestAssistantMessage
    | ChatCompletionRequestToolMessage
    | ChatCompletionRequestFunctionMessage)[];

  /** A list of tools the model may generate JSON inputs for. */
  tools?: ChatCompletionTool[];

  parallel_tool_calls?: ParallelToolCalls = true;

  /** A list of functions the model may generate JSON inputs for. */
  #deprecated "This field is marked as deprecated."
  @minItems(1)
  @maxItems(128)
  functions?: ChatCompletionFunctions[];
}

/** The per-line training example of a fine-tuning input file for completions models */
model FinetuneCompletionRequestInput {
  /** The input prompt for this training example. */
  prompt?: string;

  /** The desired completion for this training example. */
  completion?: string;
}

model FineTuneChatCompletionRequestAssistantMessage
  extends ChatCompletionRequestAssistantMessage {}
